{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580041d9-2aec-4758-97a9-0bc7b0e86c37",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "- Feature are basically what the data is, so if is a model to classify hand-writing, cursive an upper-case are examples of features\n",
    "- Apply what you know about the data, and the model, to create better features\n",
    "- Experience stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b28abb-db76-4883-ac2e-6b048279f5dd",
   "metadata": {},
   "source": [
    "## The Curse of Dimensionality\n",
    "- Too many features can be a problem - leads to sparce data\n",
    "- Every feature is a new dimension\n",
    "- Much of feature engineering is choose the most relevant feature to the problem\n",
    "- Dimensionality reduction can be useful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702d817-7df6-4691-b98b-1c9372816634",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imputing Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182c002-7bed-4965-8627-5f37cf4c269c",
   "metadata": {},
   "source": [
    "## Mean replacement\n",
    "- Replace missing values with the mean value from the rest of the column\n",
    "- Fast & Easy\n",
    "- Median may be a better choice when we have outliers\n",
    "- Generally sucks\n",
    "  - Only works on column level\n",
    "  - Cant use categorical features\n",
    "  - Not very acurate\n",
    "  - \n",
    "## Dropping\n",
    "- If not many rows contain missing data, whe can just drop that\n",
    "- BUT is just for moments whe dont have time and we have enough data\n",
    "- Almost anything is better\n",
    "\n",
    "## Machine Learning\n",
    "- KNN Find the k nearest rows and average their values\n",
    "    - Assumes numerical data\n",
    "    - There are ways to handle categorical data, but DL is better\n",
    "- Deep Learning\n",
    "    - Build a ML model to impute data for your machine learning model\n",
    "    - Works on categorical data, but its complicated\n",
    "- Regression\n",
    "    - Find linear or non-linear relations between the missing feature and other features\n",
    "    - Most advanced technique: MICE\n",
    "\n",
    "## Just get more data\n",
    "- If its possible "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ed386-1ac9-484d-90cf-9f3576f14aaf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Unbalanced data\n",
    "- Large discrepancy between \"positive\" and \"negative\" cases\n",
    "    - Ex Fraud detection\n",
    "    - Positive doesnt mean good, the thing we observe just happend\n",
    "    - If the ML model is made to detect fraud, then fraud is the positive case\n",
    "- Mainly works with neural networsks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2856c378-9045-42c6-89f7-31be69c9d820",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "- Duplicate samples from the minority class\n",
    "- Can be done at random\n",
    "\n",
    "## Undersampling\n",
    "- Instead of creating more positive samples, remove negative ones\n",
    "- Trowing data away is usually not the roght answer\n",
    "\n",
    "## SMOTE\n",
    "- Synthetic Minority Over-sampling TEchnique\n",
    "- Artificially generate samples of the minority class using nearest neighbors\n",
    "    - Run KNN for each sample of the minority class\n",
    "    - Create a new sample from the KNN result (mean of neighbors)\n",
    "- Both generate new samples and undersamples majority class\n",
    "- Generally better than just oversampling\n",
    "\n",
    "## Adjust thresholds\n",
    "- When making predictions about a classification (fraud/not fraud), you have some sort of threhold of probability at which point you'll flag something as the positive case\n",
    "- If you have too many false positives, one way to fix that is simple increase that threshold\n",
    "    - Guaranteed to reduce false positives\n",
    "    - But, could result in more false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272194c-70b5-4c3d-b9e8-bec51f841fab",
   "metadata": {},
   "source": [
    "# Binning\n",
    "- Bucket observation together based on ranges of values\n",
    "- Example: Estimated ages of peolpe\n",
    "    - Pull all 20-somethings in one classification, 30-somethings in another\n",
    "- Quantile binning categorizzes data by their place in the data distribution\n",
    "    - Ensures even sizes of bins\n",
    "- Transform numeric data to ordinal data\n",
    "- Especially useful when there is uncertainty in the measurements\n",
    "- (Like bucketsort?)\n",
    "\n",
    "# Transforming\n",
    "- Feature data with an exponential trend may benefit from a log trasnformation\n",
    "- Applying some function to make it better suited for training\n",
    "Example: YouTube recommendations\n",
    "- A numeric feature $x$ is also represent by $x^2$ and $\\sqrt{2}$\n",
    "- This allows learning og super and sub-linear functions\n",
    "\n",
    "# Encoding\n",
    "- Transform data into some new representation\n",
    "- One-hot encoding\n",
    "    - Create buckets for every category\n",
    "    - the bucket for your category has a 1, all others have 0\n",
    "    - Very commom in DL where categories are represented by individual neurons\n",
    "\n",
    "# Scaling/Normalization\n",
    "- Some models prefer featured data to be normally distributed around 0 (most neural nets)\n",
    "- Most models require feature data to at least be scaled to comparable values\n",
    "- Scikit_learn has a preprocessor module that helps (MinMaxScaler)\n",
    "- Remember to scale back up\n",
    "\n",
    "# Shuffling\n",
    "- Many algorithms benefit from shiffling their training data\n",
    "- Otherwise they may learn from residual signals in the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a5430-9866-4472-afda-ca65ee1d65be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f4827-1590-482f-a25a-8c8f420aa768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
